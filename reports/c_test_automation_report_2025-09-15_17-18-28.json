{
  "title": "ğŸš€ C Project Test Automation Report",
  "generated": "2025-09-15 17:18:28",
  "model_name": "llama-3.3-70b-versatile",
  "execution_time_seconds": 3.041433,
  "status": "SUCCESS",
  "changed_files": [
    "coverage/coverage.info",
    "main.c",
    "reports/c_run_summary.txt",
    "reports/c_test_automation_report_2025-09-15_15-50-39.json",
    "reports/c_test_automation_report_2025-09-15_15-50-39.txt",
    "reports/c_test_automation_report_2025-09-15_15-50-39.xml",
    "tests_pr/pr_generated_tests",
    "tests_pr/pr_generated_tests.c",
    "tests_pr/pr_generated_tests.gcda",
    "tests_pr/pr_generated_tests.gcno"
  ],
  "compilation_status": {
    "main.c": true,
    "generated_test_file": true
  },
  "analyzed_functions": [
    {
      "name": "add",
      "file_path": "main.c",
      "line_start": 1,
      "line_end": 5,
      "return_type": "int",
      "parameters": [
        {
          "type": "int",
          "name": "a"
        },
        {
          "type": "int",
          "name": "b"
        }
      ],
      "is_static": false,
      "is_extern": false,
      "complexity_score": 1,
      "code_snippet": "#include <stdio.h>\n\nint add(int a, int b) {\n    return a + b;\n}"
    },
    {
      "name": "main",
      "file_path": "main.c",
      "line_start": 5,
      "line_end": 18,
      "return_type": "int",
      "parameters": [],
      "is_static": false,
      "is_extern": false,
      "complexity_score": 1,
      "code_snippet": "}\n\nint main() {\n    int num1, num2, result;\n    \n    printf(\"Enter two numbers: \");\n    scanf(\"%d %d\", &num1, &num2);\n    \n    result = add(num1, num2);\n    \n    printf(\"Sum: %d\\n\", result);\n    \n    ..."
    }
  ],
  "test_results": {
    "status": "success",
    "output": "[==========] tests: Running 7 test(s).\n[ RUN      ] test_add_normal_operation\n[       OK ] test_add_normal_operation\n[ RUN      ] test_add_negative_numbers\n[       OK ] test_add_negative_numbers\n[ RUN      ] test_add_mixed_numbers\n[       OK ] test_add_mixed_numbers\n[ RUN      ] test_add_zero\n[       OK ] test_add_zero\n[ RUN      ] test_add_max_int\n[       OK ] test_add_max_int\n[ RUN      ] test_add_min_int\n[       OK ] test_add_min_int\n[ RUN      ] test_add_overflow\n[       OK ] test_add_overflow\n[==========] tests: 7 test(s) run.\n",
    "stderr": "[  PASSED  ] 7 test(s).\n",
    "test_cases": [
      {
        "name": "test_add_normal_operation",
        "status": "PASS",
        "execution_time": 0.0,
        "error_message": "",
        "failure_reason": "",
        "test_method": "test_add_normal_operation"
      },
      {
        "name": "test_add_negative_numbers",
        "status": "PASS",
        "execution_time": 0.0,
        "error_message": "",
        "failure_reason": "",
        "test_method": "test_add_negative_numbers"
      },
      {
        "name": "test_add_mixed_numbers",
        "status": "PASS",
        "execution_time": 0.0,
        "error_message": "",
        "failure_reason": "",
        "test_method": "test_add_mixed_numbers"
      },
      {
        "name": "test_add_zero",
        "status": "PASS",
        "execution_time": 0.0,
        "error_message": "",
        "failure_reason": "",
        "test_method": "test_add_zero"
      },
      {
        "name": "test_add_max_int",
        "status": "PASS",
        "execution_time": 0.0,
        "error_message": "",
        "failure_reason": "",
        "test_method": "test_add_max_int"
      },
      {
        "name": "test_add_min_int",
        "status": "PASS",
        "execution_time": 0.0,
        "error_message": "",
        "failure_reason": "",
        "test_method": "test_add_min_int"
      },
      {
        "name": "test_add_overflow",
        "status": "PASS",
        "execution_time": 0.0,
        "error_message": "",
        "failure_reason": "",
        "test_method": "test_add_overflow"
      }
    ],
    "coverage": {
      "line_coverage": 100.0,
      "function_coverage": 100.0,
      "branch_coverage": 0.0,
      "files": {
        "main.c": {
          "file": "main.c",
          "total_lines": 0,
          "covered_lines": 0,
          "line_coverage": 0.0
        },
        "tests_pr/pr_generated_tests.c": {
          "file": "tests_pr/pr_generated_tests.c",
          "total_lines": 33,
          "covered_lines": 33,
          "line_coverage": 100.0
        }
      },
      "summary": "Line coverage: 100.0% (33/33)",
      "html_report": "/home/runner/work/check-C-test/check-C-test/coverage/html/index.html",
      "total_lines": 33,
      "covered_lines": 33,
      "total_functions": 9,
      "covered_functions": 9
    }
  },
  "test_cases": [
    {
      "name": "test_add_normal_operation",
      "status": "PASS",
      "execution_time": 0.0,
      "error_message": "",
      "failure_reason": "",
      "test_method": "test_add_normal_operation"
    },
    {
      "name": "test_add_negative_numbers",
      "status": "PASS",
      "execution_time": 0.0,
      "error_message": "",
      "failure_reason": "",
      "test_method": "test_add_negative_numbers"
    },
    {
      "name": "test_add_mixed_numbers",
      "status": "PASS",
      "execution_time": 0.0,
      "error_message": "",
      "failure_reason": "",
      "test_method": "test_add_mixed_numbers"
    },
    {
      "name": "test_add_zero",
      "status": "PASS",
      "execution_time": 0.0,
      "error_message": "",
      "failure_reason": "",
      "test_method": "test_add_zero"
    },
    {
      "name": "test_add_max_int",
      "status": "PASS",
      "execution_time": 0.0,
      "error_message": "",
      "failure_reason": "",
      "test_method": "test_add_max_int"
    },
    {
      "name": "test_add_min_int",
      "status": "PASS",
      "execution_time": 0.0,
      "error_message": "",
      "failure_reason": "",
      "test_method": "test_add_min_int"
    },
    {
      "name": "test_add_overflow",
      "status": "PASS",
      "execution_time": 0.0,
      "error_message": "",
      "failure_reason": "",
      "test_method": "test_add_overflow"
    }
  ],
  "coverage_metrics": {
    "line_coverage": 100.0,
    "function_coverage": 100.0,
    "branch_coverage": 0.0,
    "files": {
      "main.c": {
        "file": "main.c",
        "total_lines": 0,
        "covered_lines": 0,
        "line_coverage": 0.0
      },
      "tests_pr/pr_generated_tests.c": {
        "file": "tests_pr/pr_generated_tests.c",
        "total_lines": 33,
        "covered_lines": 33,
        "line_coverage": 100.0
      }
    },
    "summary": "Line coverage: 100.0% (33/33)",
    "html_report": "/home/runner/work/check-C-test/check-C-test/coverage/html/index.html",
    "total_lines": 33,
    "covered_lines": 33,
    "total_functions": 9,
    "covered_functions": 9
  },
  "execution_logs": [
    "[2025-09-15 17:18:25] [INFO] ğŸš€ Starting C Project Test Automation",
    "[2025-09-15 17:18:25] [INFO] ğŸ“ Detected 10 changed files: coverage/coverage.info, main.c, reports/c_run_summary.txt, reports/c_test_automation_report_2025-09-15_15-50-39.json, reports/c_test_automation_report_2025-09-15_15-50-39.txt, reports/c_test_automation_report_2025-09-15_15-50-39.xml, tests_pr/pr_generated_tests, tests_pr/pr_generated_tests.c, tests_pr/pr_generated_tests.gcda, tests_pr/pr_generated_tests.gcno",
    "[2025-09-15 17:18:25] [INFO] ğŸ” Analyzing C file: main.c",
    "[2025-09-15 17:18:25] [INFO] âœ… Found 2 functions in main.c",
    "[2025-09-15 17:18:25] [INFO] ğŸ“Š C Function Analysis Summary:",
    "[2025-09-15 17:18:25] [INFO]    Total Functions: 2",
    "[2025-09-15 17:18:25] [INFO]    Static Functions: 0",
    "[2025-09-15 17:18:25] [INFO]    Average Complexity: 1.0/10",
    "[2025-09-15 17:18:25] [INFO] ğŸ§  Generating C test cases using llama-3.3-70b-versatile...",
    "[2025-09-15 17:18:25] [INFO] ğŸ¤– Generating C test code (attempt 1/3)...",
    "[2025-09-15 17:18:27] [SUCCESS] âœ… Generated valid-looking C test code",
    "[2025-09-15 17:18:27] [SUCCESS] âœ… Generated and saved C tests to /home/runner/work/check-C-test/check-C-test/tests_pr/pr_generated_tests.c",
    "[2025-09-15 17:18:27] [INFO] ğŸƒ Compiling and executing C tests...",
    "[2025-09-15 17:18:27] [INFO] ğŸ”¨ Compiling C tests from /home/runner/work/check-C-test/check-C-test/tests_pr/pr_generated_tests.c",
    "[2025-09-15 17:18:27] [INFO] ğŸ”§ Compilation command: gcc -std=c99 -Wall -Wextra -g --coverage -fprofile-arcs -ftest-coverage /home/runner/work/check-C-test/check-C-test/tests_pr/pr_generated_tests.c -lcmocka -lgcov -o /home/runner/work/check-C-test/check-C-test/tests_pr/pr_generated_tests -I /home/runner/work/check-C-test/check-C-test -I /home/runner/work/check-C-test/check-C-test/tests_pr",
    "[2025-09-15 17:18:27] [SUCCESS] âœ… Compilation successful",
    "[2025-09-15 17:18:27] [INFO] ğŸ§ª Executing C tests: /home/runner/work/check-C-test/check-C-test/tests_pr/pr_generated_tests",
    "[2025-09-15 17:18:27] [INFO] ğŸ“Š Generating code coverage reports...",
    "[2025-09-15 17:18:27] [INFO] ğŸ“Š Found version-specific gcov: gcov-11",
    "[2025-09-15 17:18:27] [INFO] ğŸ“Š Using gcov tool: gcov-11",
    "[2025-09-15 17:18:27] [INFO] ğŸ“Š Generating coverage for main.c...",
    "[2025-09-15 17:18:27] [SUCCESS] âœ… Coverage generated for main.c",
    "[2025-09-15 17:18:27] [INFO] ğŸ“Š Generating coverage for tests_pr/pr_generated_tests.c...",
    "[2025-09-15 17:18:27] [SUCCESS] âœ… Coverage generated for tests_pr/pr_generated_tests.c",
    "[2025-09-15 17:18:28] [SUCCESS] âœ… HTML coverage report generated",
    "[2025-09-15 17:18:28] [SUCCESS] âœ… All tests passed"
  ]
}