{
  "title": "🚀 C Project Test Automation Report",
  "generated": "2025-09-15 15:50:39",
  "model_name": "llama-3.3-70b-versatile",
  "execution_time_seconds": 144.775659,
  "status": "SUCCESS",
  "changed_files": [
    "main.c",
    "reports/c_run_summary.txt",
    "reports/c_test_automation_report_2025-09-15_15-13-45.json",
    "reports/c_test_automation_report_2025-09-15_15-13-45.txt",
    "reports/c_test_automation_report_2025-09-15_15-13-45.xml",
    "reports/c_test_automation_report_2025-09-15_15-31-10.json",
    "reports/c_test_automation_report_2025-09-15_15-31-10.txt",
    "reports/c_test_automation_report_2025-09-15_15-31-10.xml",
    "tests_pr/pr_generated_tests",
    "tests_pr/pr_generated_tests.c"
  ],
  "compilation_status": {
    "main.c": true,
    "generated_test_file": true
  },
  "analyzed_functions": [
    {
      "name": "add",
      "file_path": "main.c",
      "line_start": 1,
      "line_end": 5,
      "return_type": "int",
      "parameters": [
        {
          "type": "int",
          "name": "a"
        },
        {
          "type": "int",
          "name": "b"
        }
      ],
      "is_static": false,
      "is_extern": false,
      "complexity_score": 1,
      "code_snippet": "#include <stdio.h>\n\nint add(int a, int b) {\n    return a + b + 1;\n}"
    },
    {
      "name": "main",
      "file_path": "main.c",
      "line_start": 5,
      "line_end": 18,
      "return_type": "int",
      "parameters": [],
      "is_static": false,
      "is_extern": false,
      "complexity_score": 1,
      "code_snippet": "}\n\nint main() {\n    int num1, num2, result;\n    \n    printf(\"Enter two numbers: \");\n    scanf(\"%d %d\", &num1, &num2);\n    \n    result = add(num1, num2);\n    \n    printf(\"Sum: %d\\n\", result);\n    \n    ..."
    }
  ],
  "test_results": {
    "status": "success",
    "output": "[==========] tests: Running 5 test(s).\n[ RUN      ] test_add_normal_operation\n[       OK ] test_add_normal_operation\n[ RUN      ] test_add_negative_numbers\n[       OK ] test_add_negative_numbers\n[ RUN      ] test_add_zero\n[       OK ] test_add_zero\n[ RUN      ] test_add_max_int\n[       OK ] test_add_max_int\n[ RUN      ] test_add_min_int\n[       OK ] test_add_min_int\n[==========] tests: 5 test(s) run.\n",
    "stderr": "[  PASSED  ] 5 test(s).\n",
    "test_cases": [
      {
        "name": "test_add_normal_operation",
        "status": "PASS",
        "execution_time": 0.0,
        "error_message": "",
        "failure_reason": "",
        "test_method": "test_add_normal_operation"
      },
      {
        "name": "test_add_negative_numbers",
        "status": "PASS",
        "execution_time": 0.0,
        "error_message": "",
        "failure_reason": "",
        "test_method": "test_add_negative_numbers"
      },
      {
        "name": "test_add_zero",
        "status": "PASS",
        "execution_time": 0.0,
        "error_message": "",
        "failure_reason": "",
        "test_method": "test_add_zero"
      },
      {
        "name": "test_add_max_int",
        "status": "PASS",
        "execution_time": 0.0,
        "error_message": "",
        "failure_reason": "",
        "test_method": "test_add_max_int"
      },
      {
        "name": "test_add_min_int",
        "status": "PASS",
        "execution_time": 0.0,
        "error_message": "",
        "failure_reason": "",
        "test_method": "test_add_min_int"
      }
    ],
    "coverage": {
      "line_coverage": 0.0,
      "function_coverage": 0.0,
      "branch_coverage": 0.0,
      "files": {},
      "summary": "No coverage data available"
    }
  },
  "test_cases": [
    {
      "name": "test_add_normal_operation",
      "status": "PASS",
      "execution_time": 0.0,
      "error_message": "",
      "failure_reason": "",
      "test_method": "test_add_normal_operation"
    },
    {
      "name": "test_add_negative_numbers",
      "status": "PASS",
      "execution_time": 0.0,
      "error_message": "",
      "failure_reason": "",
      "test_method": "test_add_negative_numbers"
    },
    {
      "name": "test_add_zero",
      "status": "PASS",
      "execution_time": 0.0,
      "error_message": "",
      "failure_reason": "",
      "test_method": "test_add_zero"
    },
    {
      "name": "test_add_max_int",
      "status": "PASS",
      "execution_time": 0.0,
      "error_message": "",
      "failure_reason": "",
      "test_method": "test_add_max_int"
    },
    {
      "name": "test_add_min_int",
      "status": "PASS",
      "execution_time": 0.0,
      "error_message": "",
      "failure_reason": "",
      "test_method": "test_add_min_int"
    }
  ],
  "coverage_metrics": {
    "line_coverage": 0.0,
    "function_coverage": 0.0,
    "branch_coverage": 0.0,
    "files": {},
    "summary": "No coverage data available"
  },
  "execution_logs": [
    "[2025-09-15 15:48:15] [INFO] 🚀 Starting C Project Test Automation",
    "[2025-09-15 15:48:15] [INFO] 📁 Detected 10 changed files: main.c, reports/c_run_summary.txt, reports/c_test_automation_report_2025-09-15_15-13-45.json, reports/c_test_automation_report_2025-09-15_15-13-45.txt, reports/c_test_automation_report_2025-09-15_15-13-45.xml, reports/c_test_automation_report_2025-09-15_15-31-10.json, reports/c_test_automation_report_2025-09-15_15-31-10.txt, reports/c_test_automation_report_2025-09-15_15-31-10.xml, tests_pr/pr_generated_tests, tests_pr/pr_generated_tests.c",
    "[2025-09-15 15:48:15] [INFO] 🔍 Analyzing C file: main.c",
    "[2025-09-15 15:48:15] [INFO] ✅ Found 2 functions in main.c",
    "[2025-09-15 15:48:15] [INFO] 📊 C Function Analysis Summary:",
    "[2025-09-15 15:48:15] [INFO]    Total Functions: 2",
    "[2025-09-15 15:48:15] [INFO]    Static Functions: 0",
    "[2025-09-15 15:48:15] [INFO]    Average Complexity: 1.0/10",
    "[2025-09-15 15:48:15] [INFO] 🧠 Generating C test cases using llama-3.3-70b-versatile...",
    "[2025-09-15 15:48:15] [INFO] 🤖 Generating C test code (attempt 1/3)...",
    "[2025-09-15 15:48:16] [SUCCESS] ✅ Generated valid-looking C test code",
    "[2025-09-15 15:48:16] [SUCCESS] ✅ Generated and saved C tests to /home/runner/work/check-C-test/check-C-test/tests_pr/pr_generated_tests.c",
    "[2025-09-15 15:48:16] [INFO] 🏃 Compiling and executing C tests...",
    "[2025-09-15 15:48:16] [INFO] 🔨 Compiling C tests from /home/runner/work/check-C-test/check-C-test/tests_pr/pr_generated_tests.c",
    "[2025-09-15 15:48:16] [INFO] 🔧 Compilation command: gcc -std=c99 -Wall -Wextra -g --coverage -fprofile-arcs -ftest-coverage /home/runner/work/check-C-test/check-C-test/tests_pr/pr_generated_tests.c -lcmocka -lgcov -o /home/runner/work/check-C-test/check-C-test/tests_pr/pr_generated_tests -I /home/runner/work/check-C-test/check-C-test/tests_pr -I /home/runner/work/check-C-test/check-C-test",
    "[2025-09-15 15:48:16] [SUCCESS] ✅ Compilation successful",
    "[2025-09-15 15:48:16] [INFO] 🧪 Executing C tests: /home/runner/work/check-C-test/check-C-test/tests_pr/pr_generated_tests",
    "[2025-09-15 15:48:16] [INFO] 📊 Generating code coverage reports...",
    "[2025-09-15 15:48:16] [INFO] 📊 Generating coverage for main.c...",
    "[2025-09-15 15:48:16] [WARNING] ⚠️ Could not generate coverage for main.c: main.gcno:cannot open notes file\nmain.gcda:cannot open data file, assuming not executed\n",
    "[2025-09-15 15:48:16] [INFO] 📊 Generating coverage for tests_pr/pr_generated_tests.c...",
    "[2025-09-15 15:49:29] [WARNING] ⚠️ Could not generate coverage for tests_pr/pr_generated_tests.c: tests_pr/pr_generated_tests.gcno:version 'B15*', prefer 'B33*'\n",
    "[2025-09-15 15:50:39] [WARNING] ⚠️ lcov capture failed: stderr:\n  /home/runner/work/check-C-test/check-C-test/tests_pr/pr_generated_tests.gcno:version 'B15*', prefer 'B33*'\ngeninfo: ERROR: Incompatible GCC/GCOV version found while processing /home/runner/work/check-C-test/check-C-test/tests_pr/pr_generated_tests.gcda:\n\tYour test was built with 'B15*'.\n\tYou are trying to capture with gcov tool '/usr/bin/gcov' which is version 'B33*'.\n\t(use \"geninfo --ignore-errors version ...\" to bypass this error)\n",
    "[2025-09-15 15:50:39] [SUCCESS] ✅ All tests passed"
  ]
}